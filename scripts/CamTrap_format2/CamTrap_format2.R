# Load required packages - libraries to run the script ####

# Install necessary libraries - packages  
packagesPrev<- installed.packages()[,"Package"] # Check and get a list of installed packages in this machine aand R version
packagesNeed<- c("magrittr", "data.table", "terra", "raster", "sf", "pbapply", "this.path", "rjson", "tools", "unmarked", "reshape2", "Rcpp" , "RcppEigen", "RcppParallel", "RcppNumerical", "secr", "camtrapR") # Define the list of required packages to run the script
new.packages <- packagesNeed[!(packagesNeed %in% packagesPrev)]; if(length(new.packages)) {install.packages(new.packages, binary=T, force=T, dependencies = F, repos= "https://packagemanager.posit.co/cran/__linux__/jammy/latest")} # Check and install required packages that are not previously installed

# Load libraries
packagesList<-list("magrittr") # Explicitly list the required packages throughout the entire routine. Explicitly listing the required packages throughout the routine ensures that only the necessary packages are listed. Unlike 'packagesNeed', this list includes packages with functions that cannot be directly called using the '::' syntax. By using '::', specific functions or objects from a package can be accessed directly without loading the entire package. Loading an entire package involves loading all the functions and objects 
lapply(packagesList, library, character.only = TRUE)  # Load libraries - packages  

#### Set enviroment variables ###
# Option 1: Setting for production pipeline purposes. This is designed for use in a production environment or workflow.
Sys.setenv(outputFolder = "/path/to/output/folder")

# Option 2: Recommended for debugging purposes to be used as a testing environment. This is designed to facilitate script testing and correction
if ( (!exists("outputFolder"))  ) {
  outputFolder<- {x<- this.path::this.path();  file_prev<-  paste0(gsub("/scripts.*", "/output", x), gsub("^.*/scripts", "", x)  ); options<- tools::file_path_sans_ext(file_prev) %>% {c(., paste0(., ".R"), paste0(., "_R"))}; folder_out<- options %>% {.[file.exists(.)]} %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]}; folder_final<- list.files(folder_out, full.names = T) %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]} }
}


# Set the 'input' environment variables. The 'input' environment contains the specified inputs from the ByB platform.
# The input file 'input.json' is generated by executing the 'Run Script' command in the ByB platform.
input <- rjson::fromJSON(file=file.path(outputFolder, "input.json")) # Load input file
# This section adjusts the input values based on specific conditions to rectify and prevent errors in the input paths
input<- lapply(input, function(y) lapply(y, function(x)  { if (!is.null(x) && length(x) > 0 && grepl("/", x) && !grepl("http:", x)  ) { 
  sub("/output/.*", "/output", outputFolder) %>% dirname() %>%  file.path(x) %>% {gsub("//+", "/", .)}  } else if(!is.null(x) && length(x) > 0 && x %in% c("NULL", "NA")){NULL} else {x} }) %>% unlist()) 

#  Script body ####
## Read data input ####
camptrap_data<-  data.table::fread(input$camptrap_data) %>% readr::type_convert() %>% as.data.frame() %>%  dplyr::mutate_if(is.numeric, ~ if(all(. %in% c(0, 1))) {as.factor(.)} else {.})

## Adjust dates ####
### Ajustar formato ####
camptrap_data[, input$evendateCol]<- lubridate::parse_date_time(x = camptrap_data[, input$evendateCol], order = c("dmy", "Ymd","dmY"))
camptrap_data[, input$setupCol]<- lubridate::parse_date_time(x = camptrap_data[, input$setupCol], order = c("dmy", "Ymd","dmY"))
camptrap_data[, input$retrievalCol]<- lubridate::parse_date_time(x = camptrap_data[, input$retrievalCol], order = c("dmy", "Ymd","dmY"))
camptrap_data[, input$eventTimeCol]<-  lubridate::parse_date_time(camptrap_data[,input$eventTimeCol], orders = c("H", "H:M", "H:M:S")) %>% format(format = "%H:%M:%S")

### columna DateTimeOriginal ####
DateTimeOriginal_data<- camptrap_data %>% 
  dplyr::mutate(id_conc= seq(nrow(.))) %>% 
  dplyr::filter(!is.na(.[, input$evendateCol]), !is.na(.[, input$eventTimeCol]) ) %>% 
  dplyr::mutate(DateTimeOriginal = paste(.[,input$evendateCol], .[,input$eventTimeCol])) %>% 
  dplyr::mutate(site_id= as.character( !!rlang::sym(input$siteCol) )) %>% 
  dplyr::filter(DateTimeOriginal>= !!rlang::sym(input$setupCol) , DateTimeOriginal<= !!rlang::sym(input$retrievalCol)) # eliminar registros fuera de rango

## Camera operation ####
CTtable <- DateTimeOriginal_data %>%
  dplyr::select( c("site_id", as.character(unlist(input[c("setupCol", "retrievalCol", "cameraCol" )]))) ) %>%
  na.omit()  %>% dplyr::distinct()

camOp_matrix <- camtrapR::cameraOperation(CTtable = CTtable,
                                          setupCol = input$setupCol,
                                          retrievalCol = input$retrievalCol,
                                          stationCol = "site_id",
                                          cameraCol = input$cameraCol,
                                          byCamera = FALSE,
                                          allCamsOn = TRUE,
                                          camerasIndependent = FALSE,
                                          hasProblems  = FALSE)

## Detection history ####
recordTable<- DateTimeOriginal_data %>% dplyr::select(  c("DateTimeOriginal", "site_id", "id_conc", as.character(unlist(input[c("speciesCol","setupCol", "retrievalCol", "cameraCol" )]))) )



detHistory_matrix <- camtrapR::detectionHistory(recordTable = recordTable,
                                                speciesCol = input$speciesCol, 
                                                species = input$speciesName,
                                                camOp = camOp_matrix,
                                                stationCol = "site_id",
                                                recordDateTimeCol = "DateTimeOriginal",
                                                recordDateTimeFormat  = "%Y-%m-%d%H:%M:%S",
                                                occasionLength = input$dateCollapseLength,  #change to colaps diferent dates
                                                day1 = "station",  #first day of survey; if we want to specify a date put in "survey"
                                                datesAsOccasionNames = F,
                                                includeEffort = F, #careful if trapping effort is thought to influence detection probability, it can be returned by setting includeEffort = TRUE.
                                                scaleEffort = F, #maybe wise using T, explore later
                                                timeZone = "UTC")

### Adjust and clean Detection history ####
detHistory_matrix_adjust<- detHistory_matrix$detection_history %>% as.data.frame.matrix() %>%
  dplyr::mutate( na_cells = rowSums(is.na(.))) %>% 
  dplyr::filter(na_cells <= input$min_NAs) %>% dplyr::select(-c("na_cells")) %>% 
  dplyr::select_if(~ !all(is.na(.)))


#### explore id to table ####
seq_dates <- seq(from = min(recordTable$Instal.Date), to = max(recordTable$Last.eventDate), by = "6 days") %>% as.POSIXct( format="%Y-%m-%d")

indexTable <- recordTable %>% dplyr::select(c("DateTimeOriginal", "site_id", "id_conc")) %>%  dplyr::arrange(DateTimeOriginal) %>% 
  dplyr::mutate(occasion = cut(as.POSIXct(DateTimeOriginal), breaks=seq_dates, include.lowest=TRUE)  ) %>% 
  dplyr::mutate(oc_detHist= factor(paste0("o", as.numeric(.$occasion)), levels= colnames(detHistory_matrix_adjust)) ) %>% 
  dplyr::filter(site_id %in% rownames(detHistory_matrix_adjust) )


## Unmark data ####
data_adjust <- list(indexTable, DateTimeOriginal_data) %>% plyr::join_all(match = "all") %>% 
  dplyr::arrange(match(site_id, rownames(detHistory_matrix_adjust))) %>% 
  dplyr::filter(!is.na(oc_detHist))


### Adjust site covs ####
site_covs_input<- lapply(input$site_covs, function(y) { text_ext<- tools::file_ext(y)
if(text_ext != ""){
  if(file.exists(y)){y}else{NULL}
} else {
  test_folder<- dir.exists(y)
  if(test_folder){ list.files(y, full.names = T, recursive = F, pattern = "\\.") %>%  {.[!grepl("\\.tfw$|~$", .)]} } else { NULL }
}
})  %>% unlist()  %>%  basename() %>% tools::file_path_sans_ext()

site_covs<- site_covs_input %>% {.[. %in% names(camptrap_data)]}

site_covs_data<-   data_adjust %>%  dplyr::select(c("site_id", site_covs)) %>% 
  dplyr::group_by( site_id) %>% 
  dplyr::summarise(dplyr::across(all_of(site_covs), mean, na.rm = TRUE)) %>% tibble::column_to_rownames("site_id")



### Adjust Observation covs ####
obs_covs<- input$obs_covs %>% {Filter(function(x) {!is.null(x)}, .)}
list_obcovs<- list()

for(j in obs_covs ){
  
  string_x<- unlist(strsplit(j, "\\|")) %>% sapply(function(x) {if(x == "NULL" | x == "NA"){NULL}else{x} }) %>% unlist()
  data_obcov<- dplyr::select(data_adjust, c("site_id", "oc_detHist", string_x[1]))
  
  tryCatch({
    
    data_obcov[, "var_obcov"]<- {if( any(class(data_adjust[, string_x[1]]) %in% c("character", "factor"))  ){
      data_adjust[, string_x[1]]
    } else {
      if( is.na(as.numeric(string_x[length(string_x)]))  ){
        as.POSIXct(data_adjust[, string_x[1]], format = "%H:%M:%S")  %>% lubridate::round_date(unit = paste(string_x[2:3], collapse = " ")) 
      } else {
        if(length(string_x)<=1){
          data_adjust[, string_x[1]]
        } else {
          plyr::round_any(data_adjust[, string_x[1]], as.numeric(string_x[2]))
        }
      } 
    }
    }
    
    list_obcovs[[ as.character(string_x[1]) ]] <- reshape2::dcast(data_obcov, site_id ~ oc_detHist, value.var = "var_obcov", drop = F) %>% tibble::column_to_rownames("site_id")
    
  }, error= function(e) {NULL})
  
}







### Create unmarked data ####
umf_matrix = unmarked::unmarkedFrameOccu(y = detHistory_matrix_adjust, siteCovs = site_covs_data, obsCovs = list_obcovs)  %>% as( "data.frame") %>% as.data.frame.matrix()

## Write results ####
umf_matrix_path<- file.path(outputFolder, "umf_matrix.csv") # Define the file path for the 'val_wkt_path' output
write.csv(umf_matrix, umf_matrix_path, row.names = T ) # Write the 'val_wkt_path' output

detHistory_matrix_path<- file.path(outputFolder, "detHistory_matrix.csv") # Define the file path for the 'val_wkt_path' output
write.csv(detHistory_matrix_adjust, detHistory_matrix_path, row.names = T ) # Write the 'val_wkt_path' output


#### Outputing result to JSON ####
output<- list(detHistory_matrix=detHistory_matrix_path, umf_matrix= umf_matrix_path)

# Write the output list to the 'output.json' file in JSON format
setwd(outputFolder)
jsonlite::write_json(output, "output.json", auto_unbox = TRUE, pretty = TRUE)



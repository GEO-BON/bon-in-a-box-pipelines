# Load required packages - libraries to run the script ####

## Check and install necessary libraries - packages  ####
packagesPrev<- installed.packages()[,"Package"] # Check and get a list of installed packages in this machine and R version
packagesNeed<- c("magrittr", "devtools", "rjson", "jsonlite", "this.path", "terra", "raster", "sf", "pbapply", "gdalcubes");  packagesNeed<- packagesNeed[!packagesNeed==""]  # Define the list of required packages to run the script
new.packages <- packagesNeed[!(packagesNeed %in% packagesPrev)]; if(length(new.packages)) {install.packages(new.packages, binary=T, force=T, dependencies = F, repos= "https://packagemanager.posit.co/cran/__linux__/jammy/latest")} # Check and install required packages that are not previously installed

packagesRemotes<- c(""); packagesRemotes<- packagesRemotes[!packagesRemotes==""]  # Define the list of required packages to run that are avaliable from other sources
new.packagesRemotes <- packagesRemotes[!(packagesRemotes %in% packagesPrev)]; if(length(packagesRemotes)) {lapply(packagesRemotes, function(x) devtools::install_github(x))} # Check and install required packages that are not previously installed

## Load the necessary libraries into the script environment ####
packagesList<-list("magrittr", "terra") # Explicitly list the required packages throughout the entire routine. Explicitly listing the required packages throughout the routine ensures that only the necessary packages are listed. Unlike 'packagesNeed', this list includes packages with functions that cannot be directly called using the '::' syntax. By using '::', specific functions or objects from a package can be accessed directly without loading the entire package. Loading an entire package involves loading all the functions and objects 
lapply(packagesList, library, character.only = TRUE)  # Load libraries - packages  


# Set enviroment variables ####

### Define output folder path ####
#### Option 1: Setting for production pipeline purposes. ####
##### This is designed for use in a production environment or workflow.
Sys.setenv(outputFolder = "/path/to/output/folder")

#### Option 2: Recommended for debugging purposes to be used as a testing environment. ####
##### This is designed to facilitate script testing and correction
if ( (!exists("outputFolder"))  ) {
  outputFolder<- {x<- this.path::this.path();  file_prev<-  paste0(gsub("/scripts.*", "/output", x), gsub("^.*/scripts", "", x)  ); options<- tools::file_path_sans_ext(file_prev) %>% {c(., paste0(., ".R"), paste0(., "_R"))}; folder_out<- options %>% {.[file.exists(.)]} %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]}; folder_final<- list.files(folder_out, full.names = T) %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]} }
}

### Define input folder path ####
#### Set the 'input' environment variables. The 'input' environment contains the specified inputs from the ByB platform.
#### The input file 'input.json' is generated by executing the 'Run Script' command in the ByB platform.
input <- rjson::fromJSON(file=file.path(outputFolder, "input.json")) # Load input file

#### Adjusts the input values paths ####
##### This section adjusts the input values based on specific conditions to rectify and prevent errors in the input paths
input<- lapply(input, function(x) { if (!is.null(x) && length(x) > 0 && grepl("/", x) && !grepl("http://", x)  ) { 
  sub("/output/.*", "/output", outputFolder) %>% dirname() %>%  file.path(x) %>% {gsub("//+", "/", .)}  } else{x} }) 
input$RSTACQuery<- "https://stac.geobon.org/"
input$RSTACcollection<- "gfw-lossyear"


#  Script body ####

# Cargar area de estudio 
study_area<- terra::rast(input$StudyArea_grid) %>% terra::project(terra::crs( "+proj=longlat +datum=WGS84 +no_defs" )) # cargar raster
box_study_area <-  sf::st_bbox(study_area) # estimar extension
crs_polygon<- terra::crs( study_area ) %>% as.character() # estimar proyeccion del poligono
res_studyarea<- terra::res(study_area)

# Puente stac
RSTACQuery<- rstac::stac(input$RSTACQuery)

function_load<- function(RSTACcollection, aggregation){

# Cargar coleccion
STACItemCollection <- rstac::stac_search(q= RSTACQuery, collections = RSTACcollection, 
                                         bbox = box_study_area) %>% rstac::get_request()

# Cargar image coleccion
 assets<- unlist(rstac::items_assets(STACItemCollection))
image_collection <- gdalcubes::stac_image_collection(s=STACItemCollection$features, 
                                                     asset_names = assets,
                                                     srs = crs_polygon)

t0<- gdalcubes::extent(image_collection)$t0
t1<- gdalcubes::extent(image_collection)$t1

cube_collection<- gdalcubes::cube_view(srs = crs_polygon,  extent = list(t0 = t0, t1 = t1,
                                                                         left = box_study_area[1], right = box_study_area[3],
                                                                         top = box_study_area[4], bottom = box_study_area[2]),
                                       dx = res_studyarea[1], dy = res_studyarea[2], dt = "P1Y", aggregation = aggregation, resampling = "near",
                                       keep.asp= F)

# Load cube
wkt_file<- vecto %>% sf::st_as_sf() %>% sf::st_set_geometry("geometry") %>%  {sf::st_as_text(.$geometry)}
cube <- gdalcubes::raster_cube(image_collection, cube_collection) %>% filter_geom()

# Download cube
fn = tempfile(fileext = ".nc"); gdalcubes::write_ncdf(cube, fn)

# Data cubo
bands_cube <- names(cube)
times<- gdalcubes::dimension_bounds(cube)[["t"]] %>% as.data.frame() %>% dplyr::mutate(time= paste0(start, "_", end))

list_vars<- pblapply(bands_cube, function(x) { print(x)
  var_layer <- raster::brick(fn, var= x) %>% terra::rast() %>% setNames(paste0(x, "_", times$time))
  test_layer<- terra::freq(var_layer) %>% dplyr::filter(!is.na(value)) %>% {unique(.$layer)}
  var_layer[[test_layer]]   }) %>% terra::rast()

}


# Cargar colecciones de interes
loss_year<- function_load(RSTACcollection = "gfw-lossyear", aggregation= "min")
chelsa_clim<- function_load(RSTACcollection = "chelsa-clim", aggregation= "mean")




# Tiempo1
i_year<- data.frame(i= seq(0, 22, 1)) %>% dplyr::mutate(year= paste0(dplyr::if_else(i<=9, "200", "20"),i))
t1_i<- dplyr::filter(i_year, year== as.character(input$year))
test_loss_T1 <- terra::ifel(loss_year == t1_i$i,1, NA)


plot(loss_year, main= "loss_year")
plot(test_loss_T1, main= paste0("loss_year ", as.character(input$year)))
plot(chelsa_clim, main= paste0("chelsa_clim covars"))














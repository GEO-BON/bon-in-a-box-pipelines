#### Load required packages - libraries to run the script ####

# Install necessary libraries - packages 
packagesPrev<- installed.packages()[,"Package"] # Check and get a list of installed packages in this machine and R version
packagesNeed<-list("rstudioapi", "magrittr", "dplyr", "plyr",  "raster", "terra", "auk",
                   "vapour", "sf","tools","gdalUtilities", "tibble", "lubridate", "gridExtra", "tidyverse", "conflicted", 
                   "dggridR", "unmarked", "ebirdst", "MuMIn", "AICcmodavg", "fields", "rgdal", "janitor", "ggplot2")
lapply(packagesNeed, function(x) {   if ( ! x %in% packagesPrev ) { install.packages(x, force=T)}    }) # Check and install required packages that are not previously installed

# Load libraries
packagesList<-list("magrittr", "terra", "auk","MuMIn", "AICcmodavg", "raster", "ggplot2", "janitor") # Explicitly list the required packages throughout the entire routine. Explicitly listing the required packages throughout the routine ensures that only the necessary packages are listed. Unlike 'packagesNeed', this list includes packages with functions that cannot be directly called using the '::' syntax. By using '::', specific functions or objects from a package can be accessed directly without loading the entire package. Loading an entire package involves loading all the functions and objects 
lapply(packagesList, library, character.only = TRUE)  # Load libraries - packages


#### Set enviroment variables ####

# Set the 'outputFolder' environment variables
# The environment variable refers to the path of the output folder for the entire routine
# 'outputFolder' allows interaction with the output folder of the routine and access to nearby paths, such as the input folder ('input')

# There are two options to set 'outputFolder'
# Please select only one of the two options, while silencing the other with the '#' syntaxis: 

# Option 1: Setting for production pipeline purposes. This is designed for use in a production environment or workflow.
Sys.getenv("SCRIPT_LOCATION")

# Option 2: Recommended for debugging purposes to be used as a testing environment. This is designed to facilitate script testing and correction
# 

if(!exists("outputFolder")){
  outputFolder<- {x<- this.path::this.path();  file_prev<-  paste0(gsub("/scripts.*", "/output", x), gsub("^.*/scripts", "", x)  ); options<- list.files(dirname(file_prev), full.names  = T); folder_out<- options %>% {.[file.exists(.)]} %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]}; folder_final<- list.files(folder_out, full.names = T) %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]} }
  check_input<- T} else {check_input<- F}

# Set the 'input' environment variables. The 'input' environment contains the specified inputs from the ByB platform.
# The input file 'input.json' is generated by executing the 'Run Script' command in the ByB platform.
input <- rjson::fromJSON(file=file.path(outputFolder, "input.json")) # Load input file

# This section adjusts the input values based on specific conditions to rectify and prevent errors in the input paths
if(check_input) {input<- lapply(input, function(x) unlist(lapply(x, function(y) {
  if( grepl("/", y)  ){ sub("/output/.*", "/output", outputFolder) %>% dirname() %>%  file.path(y) %>% {gsub("//+", "/", .)}  }else{y}
}), recursive = F)) } # adjust input 1



output<- tryCatch({
  
  #### Set enviroment variables ####
  
  # Set the 'outputFolder' environment variables
  # The environment variable refers to the path of the output folder for the entire routine
  # 'outputFolder' allows interaction with the output folder of the routine and access to nearby paths, such as the input folder ('input')
  
  # There are two options to set 'outputFolder'
  # Please select only one of the two options, while silencing the other with the '#' syntaxis: 
  
  # Load data in eBird fortmat to unmarked
  occ_wide<- read.delim(input$auk_covars_file)
  #occ_wide<- read.table("occ_wide.txt", sep= "\t")
  ####  Script body ####
  #unmarked object
  occ_um <- unmarked::formatWide(dfin= occ_wide, type = "unmarkedFrameOccu")
  summary(occ_um)
  # Occupancy modeling
  #####################
  # fit model
  occ_model <- unmarked::occu(~ duration_minutes
                              ~ huella + altitud, 
                              data = occ_um)
  
  
  
  
  # look at the regression coefficients from the model
  summary(occ_model)
  # look at the regression coefficients from the model
  res_occ<-summary(occ_model)
  state<- as.data.frame(res_occ$state)
  det<- as.data.frame(res_occ$det)
  #write.table(state,"occ_state.txt", sep= "\t", row.names = TRUE)
  #write.csv(state, "occ_state.csv")
  #occ_det<- write.table("occ_det.txt", sep= "\t", header = TRUE, row.names = 1)
  #write.csv(det, "occ_det.csv")
  #######################
  # Assessment
  #####################
  occ_gof <- AICcmodavg::mb.gof.test(occ_model, nsim = input$nsim, plot.hist = FALSE)
  # hide the chisq table to give simpler output
  sa<-occ_gof$chisq.table <- NULL
  print(occ_gof)
  # Other results
  #boot::inv.logit(coef(occ_model)[1]) # Real estimate of occupancy
  #boot::inv.logit(coef(occ_model)[4]) # Real estimate of detection
  resultados<-(plogis(   MuMIn::coeffs(occ_model)       ))
  resultados<- data.frame(resultados)
  #library(tibble)
  #resultados<-resultados %>% rownames_to_column(var="Det_Occ")
  #resultados_plot<- resultados %>% filter(Det_Occ == "psi(Int)" | Det_Occ == "p(Int)")
  
  ##################
  #Model selection
  #################
  # dredge all possible combinations of the occupancy covariates
  occ_dredge <- MuMIn::dredge(occ_model)
  
  
  # model comparison to explore the results for occupancy
  mc <- as.data.frame(occ_dredge) %>% 
    dplyr::select(starts_with("psi(p"), df, AICc, delta, weight)
  # model comparison
  # model comparison to explore the results for occupancy
  mc <- as.data.frame(occ_dredge) %>% 
    dplyr::select(starts_with("psi(p"), df, AICc, delta, weight)
  # shorten names for printing
  names(mc) <- names(mc) %>% 
    stringr::str_extract("(?<=psi\\(pland_[0-9]{2}_)[a-z_]+") %>% 
    dplyr::coalesce(names(mc))
  # take a quick peak at the model selection table
  dplyr::mutate_all(mc, ~ round(., 3)) %>% 
    head(18) %>% 
    knitr::kable()
  
  
  
  # BREAK script if delr <= 2.5
  
  # export result
  #write.csv(mc, "model_selection.csv")
  #write.table("model_selection.txt", sep= "\t", header = TRUE, row.names = 1)
  # select models with the most support for model averaging (< 2.5 delta aicc)
  occ_dredge_delta <- MuMIn::get.models(occ_dredge, subset = delta <= 80)
  # average models based on model weights 
  occ_avg <- MuMIn::model.avg(occ_dredge_delta, fit = TRUE)
  # model averaged coefficients for occupancy and detection probability
  coef(occ_avg)
  ##################
  #Exploring the effects of covariates on detection probability
  ##################
  # model comparison to explore the results for detection
  md <- as.data.frame(occ_dredge) %>% 
    dplyr::select(starts_with("p("), df, AICc, delta, weight)
  # shorten names for printing
  names(md) <- names(md) %>% 
    stringr::str_extract("(?<=p\\(pland_[0-9]{2}_)[a-z_]+") %>% 
    dplyr::coalesce(names(md))
  # take a quick peak at the model selection table
  md[1:8,]
  
  coef(occ_avg) %>% 
    tibble::enframe() 
  
  ##########
  #Prediction
  ##########
  # Load data of prediction surface
  # pred_surface<- read.delim(input$pred_surface, row.names = 1)
  pred_surface <- read.csv(input$pred_surface)
  
  covars<- c("id", "Longitude", "Latitude", input$covars)
  pred_surface_selec<-pred_surface %>% dplyr::select(covars)
  
  # note: the code below can take up to an hour to run!
  occ_pred <- predict(occ_avg, 
                      newdata = as.data.frame(pred_surface_selec), 
                      type = "state")
  
  # add to prediction surface
  pred_occ <- dplyr::bind_cols(pred_surface, 
                               occ_prob = occ_pred$fit, 
                               occ_se = occ_pred$se.fit) %>% 
    dplyr::select(Latitude, Longitude, occ_prob, occ_se)
  
  ## Raster points using the predicciotn surface raster template
  base_grid <- raster(input$base_grid)
  
  
  r_pred <- pred_occ %>% 
    # convert to spatial features
    sf::st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
    sf::st_transform(crs = raster::projection(base_grid)) %>% 
    # rasterize
    raster::rasterize(base_grid)
  r_pred <- r_pred[[c("occ_prob", "occ_se")]]
  
  
  # export graph
  occprob_raster_path<- file.path(outputFolder, "occupancy-model_prob.tif") # Define the file path for the 'val_wkt_path' output
  occprob_raster<-writeRaster(r_pred[["occ_prob"]], occprob_raster_path, overwrite = TRUE) # occ prop map
  #### Outputing result to JSON ####
  output<- list(occprob_raster_export = occprob_raster_path)
  
  occse_raster_path<- file.path(outputFolder, "occupancy-model_prob.tif") # Define the file path for the 'val_wkt_path' output
  occse_raster<-writeRaster(r_pred[["occ_se"]], occse_raster_path, overwrite = TRUE) # se map
  #### Outputing result to JSON ####
  output<- list(occse_raster_export = occse_raster_path)
  
  
  # save the raster
  #tif_dir <- "output"
  #if (!dir.exists(tif_dir)) {
  #  dir.create(tif_dir)
  #}
  #writeRaster(r_pred[["occ_prob"]], 
  #            filename = file.path(tif_dir, "occupancy-model_prob_Tyrannus_melanchilicus.tif"),
  #            overwrite = TRUE)
  #writeRaster(r_pred[["occ_se"]], 
  #            filename = file.path(tif_dir, "occupancy-model_se_Tyrannus_melanchilicus.tif"), 
  #            overwrite = TRUE)
  #######
  #Graphs
  #######
  #List occupacy covaraibles 
  occformulaList<- lapply(input$covars, function(y) paste0("~1~", y) %>% as.character)
  
  
  
  
  
  
  #get obsCovs as data.frame
  siteCovs.df<-as.data.frame(occ_um@siteCovs)
  #now fit models
  
  #create empty list to save predicted detection Probs
  occCovariatePredOcc<-list()
  
  #for loop to iterate over detection covariates and produce predicted estimates for detection prob
  for(i in 1:length(occformulaList)){
    
    adjust_form<- as.formula(occformulaList[[i]])
    
    print(occformulaList[[i]])
    new.occ_model <- occu(adjust_form,  data=occ_um)
    
    #get det covariate name
    varName<-input$covars[i]
    
    #get range of values from data to simulate new data
    varData<-siteCovs.df[,names(siteCovs.df)==varName]
    
    #simulate new data
    sim.data<-data.frame(seq(min(varData,na.rm=TRUE), max(varData,na.rm=TRUE),length.out=100))
    colnames(sim.data)<-c(varName)
    #get predicted values using sim.data
    pred.df<-predict(new.occ_model, type="state", newdata=sim.data, appendData=TRUE)
    colnames(pred.df)[5]<-"occ_cov"
    
    #add column with covariate name
    pred.df$CovariateName<-varName
    
    occCovariatePredOcc<-rbind(occCovariatePredOcc, pred.df)
    
  }
  
  #make CovariateName a factor
  occCovariatePredOcc$CovariateName<-as.factor(occCovariatePredOcc$CovariateName)
  
  # Plot it
  occPlot<-ggplot(data=occCovariatePredOcc)+
    geom_ribbon(aes(x=occ_cov, ymin=lower, ymax=upper), fill="gray80")+
    geom_line(aes(x=occ_cov, y=Predicted),color="seagreen4")+
    labs(x="Covariate Values", y="Probability of Site Occupancy")+
    #ylim(0,1)+
    theme(panel.border=element_rect(color="black",fill="transparent"), panel.background = element_rect(fill="white"))
  
  occPlotFacet<-occPlot+facet_wrap(.~CovariateName, scales="free",ncol=3)
  occPlotFacet
  # export graph
  occPlotFacet_path<- file.path(outputFolder, "occ_plot.jpeg") # Define the file path for the 'val_wkt_path' output
  jpeg("occ_plot.jpeg", quality = 300)  # plot graph
  
  #### Outputing result to JSON ####
  
  
  # Final table and VEB 
  # create classification matrix
  reclass_df <- c(0, 0.2, 1,
                  0.2, 0.4, 2,
                  0.4, 0.6, 3,
                  0.6, 0.8, 4,
                  0.8, 1, 5)
  # reshape the object into a matrix with columns and rows
  reclass_m <- matrix(reclass_df,
                      ncol = 3,
                      byrow = TRUE)
  # reclassify the raster using the reclass object - reclass_m
  chm_classified <- reclassify(occprob_raster,
                               reclass_m)
  # Calculate area after clasification
  tbl<-rasterToPoints(chm_classified, spatial = FALSE)
  tbl<-tibble::as_tibble(tbl)
  tbl<-setNames(tbl, c('x','y', 'occ'))
  #tbl<- filter(tbl, occ >0)
  #summarize
  rsult<- tbl %>% 
    dplyr::group_by(occ) %>% 
    dplyr::summarise(count = dplyr::n()) %>% 
    dplyr::ungroup() 
  
  
  #pixel to kilometer
  rsult$area <- rsult$count * 0.1
  rsult$percent = round(100 * rsult$area / sum(rsult$area), 1)
  rsult$range <- c('0.0<Ψ≤0.2', '0.2<Ψ≤0.4', '0.4<Ψ≤0.6', '0.6<Ψ≤0.8', '0.8<Ψ≤1')[seq(nrow(rsult))]
  # get final table report 
  final<- data.frame(rsult$range, rsult$area, rsult$percent)
  names(final) <- c("Range", "Area (Km²)", "Pergentage")
  final<- final %>% janitor::adorn_totals("row")
  # get occupancy area VEB
  VEB<- rsult %>% dplyr::filter(range== "0.6<Ψ≤0.8" | range== "0.8<Ψ≤1") %>% 
    dplyr::summarize(VEB = sum(area))
  FVEB <- paste0("Occupancy area VEB (Ψ>0.6) = ", VEB$VEB, " Km²")
  
  #####
  final_path<- file.path(outputFolder, "final.csv") # Define the file path for the 'val_wkt_path' output
  write.csv(final, final_path, row.names = T ) # Write the 'val_wkt_path' output
  #### Outputing result to JSON ####
  
  
  VEB_path<- file.path(outputFolder, "VEB.csv") # Define the file path for the 'val_wkt_path' output
  write.csv(FVEB, VEB_path, row.names = T ) # Write the 'val_wkt_path' output
  
  
  
  #### Outputing result to JSON ####
  output<- list(occPlotFacet_export = occprob_raster_path, occPlotFacet= occPlotFacet_path,
                final_export = final_path, VEB_export = VEB_path)
  
}, error = function(e) { list(error= conditionMessage(e)) })



#### Outputing result to JSON ####

# Write the output list to the 'output.json' file in JSON format
setwd(outputFolder)
jsonlite::write_json(output, "output.json", auto_unbox = TRUE, pretty = TRUE)

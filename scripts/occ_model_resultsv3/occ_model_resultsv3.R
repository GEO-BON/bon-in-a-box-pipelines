#### Load required packages - libraries to run the script ####

# Install necessary libraries - packages 
packagesPrev<- installed.packages()[,"Package"] # Check and get a list of installed packages in this machine and R version
packagesNeed<-c("magrittr", "data.table", "tools", "Rcpp", "this.path", "rjson", "dplyr", "plyr",  "raster", "terra", "auk",
                   "lme4", "minqa", "nloptr", "unmarked", "MuMIn", "VGAM", "AICcmodavg", "ggplot2", "janitor", "snakecase")
new.packages <- packagesNeed[!(packagesNeed %in% packagesPrev)]; if(length(new.packages)) {install.packages(new.packages, binary=T, force=T, dependencies = F, repos= "https://packagemanager.posit.co/cran/__linux__/jammy/latest")} # Check and install required packages that are not previously installed

# Load libraries
packagesList<-list("magrittr", "terra", "unmarked", "auk","MuMIn", "AICcmodavg", "raster", "ggplot2") # Explicitly list the required packages throughout the entire routine. Explicitly listing the required packages throughout the routine ensures that only the necessary packages are listed. Unlike 'packagesNeed', this list includes packages with functions that cannot be directly called using the '::' syntax. By using '::', specific functions or objects from a package can be accessed directly without loading the entire package. Loading an entire package involves loading all the functions and objects 
lapply(packagesList, library, character.only = TRUE)  # Load libraries - packages

#### Set enviroment variables ###
# Option 1: Setting for production pipeline purposes. This is designed for use in a production environment or workflow.
Sys.setenv(outputFolder = "/path/to/output/folder")

# Option 2: Recommended for debugging purposes to be used as a testing environment. This is designed to facilitate script testing and correction
if ( (!exists("outputFolder"))  ) {
  outputFolder<- {x<- this.path::this.path();  file_prev<-  paste0(gsub("/scripts.*", "/output", x), gsub("^.*/scripts", "", x)  ); options<- tools::file_path_sans_ext(file_prev) %>% {c(., paste0(., ".R"), paste0(., "_R"))}; folder_out<- options %>% {.[file.exists(.)]} %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]}; folder_final<- list.files(folder_out, full.names = T) %>% {.[which.max(sapply(., function(info) file.info(info)$mtime))]} }
}

# Set the 'input' environment variables. The 'input' environment contains the specified inputs from the ByB platform.
# The input file 'input.json' is generated by executing the 'Run Script' command in the ByB platform.
input <- rjson::fromJSON(file=file.path(outputFolder, "input.json")) # Load input file

# This section adjusts the input values based on specific conditions to rectify and prevent errors in the input paths
input<- lapply(input, function(y) lapply(y, function(x)  {if (!is.null(x) && length(x) > 0 && grepl("/", x) && !grepl("http:", x)  ) { 
  sub("/output/.*", "/output", outputFolder) %>% dirname() %>%  file.path(x) %>% {gsub("//+", "/", .)}  } else if(!is.null(x) && length(x) > 0 && x %in% c("NULL", "NA")){NULL} else {x} }) %>% unlist()) 


#  Script body ####

## Cargar datos
occ_wide<- data.table::fread(input$auk_covars_file) %>% tibble::column_to_rownames(names(.)[1])


## Ajustar covariables
site_covs_input<- lapply(input$site_covs, function(y) { text_ext<- tools::file_ext(y)
if(text_ext != ""){
  if(file.exists(y)){y}else{NULL}
} else {
  test_folder<- dir.exists(y)
  if(test_folder){ list.files(y, full.names = T, recursive = F, pattern = "\\.") %>%  {.[!grepl("\\.tfw$|~$", .)]} } else { NULL }
}
})  %>% unlist()  %>%  basename() %>% tools::file_path_sans_ext()

site_covs<- site_covs_input %>% {.[. %in% names(occ_wide)]}
covs_detection<- input$obs_covs %>% {Filter(function(x) {!is.null(x)}, .)} %>% sapply(function(x) unlist(strsplit(x, "\\|"))[1]   ) %>% as.character() %>% {Filter(function(x) {!is.null(x)}, .)}


occ_wide_scale<- occ_wide
list_scale<- list()

for(j in site_covs){
  occ_wide_scale[, j]<- scale(occ_wide_scale[, j])
  list_scale[[j]]<- list(center= attr(  occ_wide_scale[, j], "scaled:center"), scale= attr(  occ_wide_scale[, j], "scaled:scale") )
}

occ_um<- occ_wide_scale  %>% unmarked::formatWide(obsToY= NULL, type = "unmarkedFrameOccu")



formula_occ<- as.formula( paste0("~ ", ifelse(length(covs_detection)>0, paste0( covs_detection, collapse = " + "), 1), " ~ ", paste0( site_covs, collapse = " + ")) )

formula_occ
om1 <- occu(~1 ~1, occ_um)
simple_coef <- coef(om1)

start_vals <- c(simple_coef[1], rep(0, length(site_covs)), simple_coef[2], rep(0, length(covs_detection)) )
occ_model <- occu(formula_occ, data = occ_um, starts = start_vals)

occ_dredge <- MuMIn::dredge(occ_model)

  
  
occ_dredge_delta <- MuMIn::get.models(occ_dredge, subset = delta <= 1000)

# average models based on model weights 
test_models<- dplyr::filter(as.data.frame(occ_dredge), delta <= 1000)
  
occ_avg<- if(nrow(test_models)<=1){
    occ_dredge_delta[[1]]
  } else {
    MuMIn::model.avg(occ_dredge_delta, fit = TRUE)
  }
    

  #Exploring the effects of covariates on detection probability
  # model comparison to explore the results for detection
  md <- as.data.frame(occ_dredge) %>% 
    dplyr::select(starts_with("p("), df, AICc, delta, weight)
  # shorten names for printing
  names(md) <- names(md) %>% 
    stringr::str_extract("(?<=p\\(pland_[0-9]{2}_)[a-z_]+") %>% 
    dplyr::coalesce(names(md))

  
  
  
  
  ##########
  #Prediction
  ##########
  # Load data of prediction surface
  site_covs_Layers<- input$site_covs_Layers %>% setNames(basename(tools::file_path_sans_ext(.)))
  spatial_pred_surface<- site_covs_Layers[ names(site_covs_Layers) %>%  {.[. %in% site_covs]} ] %>% terra::rast() %>% setNames(site_covs)
  
  
  
  id_cells<- terra::cells(spatial_pred_surface) 
  pred_surface <- spatial_pred_surface[id_cells] 
  
  pred_surface_scale<- pred_surface
  
  for(j in names(pred_surface)){
    pred_surface_scale[, j]<- scale(pred_surface_scale[, j], center= list_scale[[j]]$center, scale= list_scale[[j]]$scale)
  }
  
  
  
  # note: the code below can take up to an hour to run!
  occ_pred <- predict(occ_avg,  newdata = pred_surface ,  type = "state")

  ## Raster points using the predicciotn surface raster template
  base_grid <- terra::rast(spatial_pred_surface[[1]])
  
  r_pred_occ_prob<- base_grid
  r_pred_occ_prob[id_cells]<- occ_pred[[1]]
  
  r_pred_occ_se<- base_grid
  r_pred_occ_se[id_cells]<- occ_pred[[2]]
  
  
  
  

  # save the raster
  
  # export rasters
  occprob_raster_path<- file.path(outputFolder, "occupancy_model_prob.tif") # Define the file path for the 'val_wkt_path' output
  occprob_raster<-writeRaster(r_pred_occ_prob, occprob_raster_path, overwrite = TRUE) # occ prop map

  occse_raster_path<- file.path(outputFolder, "occupancy_se_model_prob.tif") # Define the file path for the 'val_wkt_path' output
  occse_raster<-writeRaster(r_pred_occ_se, occse_raster_path, overwrite = TRUE) # se map
  

  
  
  
  #######
  #Graphs
  #######
  #List occupacy covaraibles 
  occformulaList<- lapply(site_covs, function(y) paste0("~1~", y) %>% as.character)
  
  #get obsCovs as data.frame
  siteCovs.df<-as.data.frame(occ_um@siteCovs)
  #now fit models
  
  #create empty list to save predicted detection Probs
  occCovariatePredOcc<-list()
  
  #for loop to iterate over detection covariates and produce predicted estimates for detection prob
  for(i in 1:length(occformulaList)){
    
    adjust_form<- as.formula(occformulaList[[i]])
    
    print(occformulaList[[i]])
    new.occ_model <- unmarked::occu(adjust_form,  data=occ_um)
    
    #get det covariate name
    varName<- site_covs[i]
    
    #get range of values from data to simulate new data
    varData<-siteCovs.df[,names(siteCovs.df)==varName]
    
    #simulate new data
    sim.data<-data.frame(seq(min(varData,na.rm=TRUE), max(varData,na.rm=TRUE),length.out=100))
    colnames(sim.data)<-c(varName)
    #get predicted values using sim.data
    pred.df<-predict(new.occ_model, type="state", newdata=sim.data, appendData=TRUE)
    colnames(pred.df)[5]<-"occ_cov"
    
    #add column with covariate name
    pred.df$CovariateName<-varName
    
    occCovariatePredOcc<-rbind(occCovariatePredOcc, pred.df)
    
  }
  
  
  
  
  #make CovariateName a factor
  occCovariatePredOcc$CovariateName<-as.factor(occCovariatePredOcc$CovariateName)
  
  # Plot it
  occPlot<-ggplot(data=occCovariatePredOcc)+
    geom_ribbon(aes(x=occ_cov, ymin=lower, ymax=upper), fill="gray80")+
    geom_line(aes(x=occ_cov, y=Predicted),color="seagreen4")+
    labs(x="Covariate Values", y="Probability of Site Occupancy")+
    #ylim(0,1)+
    theme(panel.border=element_rect(color="black",fill="transparent"), panel.background = element_rect(fill="white"))
  
  occPlotFacet<-occPlot+facet_wrap(.~CovariateName, scales="free",ncol=3)
  
  # export graph
  occPlotFacet_path<- file.path(outputFolder, "occ_plot.jpeg") # Define the file path for the 'val_wkt_path' output
  ggsave(occPlotFacet_path, occPlotFacet, dpi= 300, bg= "white")
  
  
  
  #### Outputing result to JSON ####
  
  
  # Final table and VEB 
  # create classification matrix
  reclass_df <- c(0, 0.2, 1,
                  0.2, 0.4, 2,
                  0.4, 0.6, 3,
                  0.6, 0.8, 4,
                  0.8, 1, 5)
  
  
  # reshape the object into a matrix with columns and rows
  reclass_m <- matrix(reclass_df,
                      ncol = 3,
                      byrow = TRUE)
  
  
  # reclassify the raster using the reclass object - reclass_m
  chm_classified <- reclassify( raster::raster(occprob_raster), reclass_m)
  
  # Calculate area after clasification
  tbl<-rasterToPoints(chm_classified, spatial = FALSE)
  tbl<-tibble::as_tibble(tbl)
  tbl<-setNames(tbl, c('x','y', 'occ'))
  #tbl<- filter(tbl, occ >0)
  #summarize
  rsult<- tbl %>% 
    dplyr::group_by(occ) %>% 
    dplyr::summarise(count = dplyr::n()) %>% 
    dplyr::ungroup() 
  
  
  #pixel to kilometer
  rsult$area <- rsult$count * 0.1
  rsult$percent = round(100 * rsult$area / sum(rsult$area), 1)
  rsult$range <- c('0.0<Ψ≤0.2', '0.2<Ψ≤0.4', '0.4<Ψ≤0.6', '0.6<Ψ≤0.8', '0.8<Ψ≤1')[seq(nrow(rsult))]
  # get final table report 
  final<- data.frame(rsult$range, rsult$area, rsult$percent)
  names(final) <- c("Range", "Area (Km²)", "Percentage")
  final<- final %>% janitor::adorn_totals("row")
  # get occupancy area VEB
  VEB<- rsult %>% dplyr::filter(range== "0.6<Ψ≤0.8" | range== "0.8<Ψ≤1") %>% 
    dplyr::summarize(VEB = sum(area))
  FVEB <- paste0("Occupancy area VEB (Ψ>0.6) = ", VEB$VEB, " Km²")
  
  #####
  final_path<- file.path(outputFolder, "final.csv") # Define the file path for the 'val_wkt_path' output
  write.csv(final, final_path, row.names = T ) # Write the 'val_wkt_path' output

  summary_occ_path<- file.path(outputFolder, "summary_occModel.txt") # Define the file path for the 'val_wkt_path' output
  
  sink(summary_occ_path)
  print(occ_model)
  sink()
  
  #### Outputing result to JSON ####
  output<- list(occprob_raster_export  = occprob_raster_path,
                occse_raster_export = occse_raster_path,
                occPlotFacet= occPlotFacet_path,
                final_export = final_path, VEB_export = FVEB,
                summary_occ_path= summary_occ_path)
  



#### Outputing result to JSON ####

# Write the output list to the 'output.json' file in JSON format
setwd(outputFolder)
jsonlite::write_json(output, "output.json", auto_unbox = TRUE, pretty = TRUE)
